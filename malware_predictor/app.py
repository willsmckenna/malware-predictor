import pandas as pd
from sklearn import neighbors, tree
from sklearn.model_selection import train_test_split
import math
import mmap
import pefile
from sklearn import preprocessing
import numpy as np

##################################################################################################################
# Helper functions for getting the file ready for prediction ###########################
##################################################################################################################

# Calculating entropy- from https://kennethghartman.com/calculate-file-entropy/
def calculate_entropy(filepath):
    # read the whole file into a byte array
    f = open(filepath, "rb")
    byteArr = f.read()
    f.close()
    fileSize = len(list(byteArr))

    # calculate the frequency of each byte value in the file
    freqList = []
    for b in range(256):
        ctr = 0
        for byte in byteArr:
            if byte == b:
                ctr += 1
        freqList.append(float(ctr) / fileSize)

    # Shannon entropy
    ent = 0.0
    for freq in freqList:
        if freq > 0:
            ent = ent + freq * math.log(freq, 2)
    ent = -ent

    return ent


def force_decode(string, codecs=["utf8", "cp1252"]):
    for i in codecs:
        try:
            return string.decode(i)
        except UnicodeDecodeError:
            pass


def create_col_unusual_names(df):
    important_names = ['UPX0', 'petite', 'UPX1', '.imports', '.aspack', 'UPX2', '.kofbl', 'BSS', '.MPRESS1', '.MPRESS2',
                       'tkjdelw', 'ajelhf', 'coderpub', '.l1', 'CODE']

    important_names_arr = np.array(important_names)

    df['unusual_names'] = None

    for idx, row in df.iterrows():
        pe_name_data = row.pe_section_names
        pe_name_data = pe_name_data.replace("(", "")
        pe_name_data = pe_name_data.replace(")", "")
        section_arr = np.array(pe_name_data.split())
        if pd.Series(section_arr).isin(important_names_arr).any():
            df.loc[idx, 'unusual_names'] = "yes"
        else:
            df.loc[idx, 'unusual_names'] = "no"


def add_dummy_features(df):
    if 'unusual_names_yes' not in df:
        df['unusual_names_yes'] = '0'
    if 'unusual_names_no' not in df:
        df['unusual_names_no'] = '0'
    if 'machine_332' not in df:
        df['machine_332'] = '0'
    if 'machine_34404' not in df:
        df['machine_34404'] = '0'
    if 'image_base_4128768' not in df:
        df['image_base_4128768'] = '0'
    if 'image_base_4194304' not in df:
        df['image_base_4194304'] = '0'
    if 'image_base_268435456' not in df:
        df['image_base_268435456'] = '0'
    if 'image_base_5368709120' not in df:
        df['image_base_5368709120'] = '0'
    if 'section_align_4096' not in df:
        df['section_align_4096'] = '0'
    if 'section_align_8192' not in df:
        df['section_align_8192'] = '0'
    if 'file_align_512' not in df:
        df['file_align_512'] = '0'
    if 'file_align_4096' not in df:
        df['file_align_4096'] = '0'


def parse_file(filepath):
    if filepath.endswith('.exe'):
        fd = open(file_path, "rb")
        pe_data = mmap.mmap(fd.fileno(), 0, access=mmap.ACCESS_READ)
        pe = pefile.PE(data=pe_data)

        # getting PE section names for the file
        section_names = []

        for section in pe.sections:
            section_name = force_decode(section.Name)
            section_names.append(section_name)

        # getting the entropy of the file
        entropy = calculate_entropy(file_path)
        # PE header info
        machine = pe.FILE_HEADER.Machine
        time_date_stamp = pe.FILE_HEADER.dump_dict()["TimeDateStamp"]["Value"].split("[")[
                              1
                          ][:-1]
        number_of_sections = pe.FILE_HEADER.NumberOfSections
        characteristics = pe.FILE_HEADER.Characteristics
        # Optional header info
        image_base = pe.OPTIONAL_HEADER.ImageBase
        section_allign = pe.OPTIONAL_HEADER.SectionAlignment
        file_allign = pe.OPTIONAL_HEADER.FileAlignment
        size_of_image = pe.OPTIONAL_HEADER.SizeOfImage
        dll_chars = pe.OPTIONAL_HEADER.DllCharacteristics

        # add features to the dataframe
        file_to_predict = pd.DataFrame.from_records([{'pe_section_names': "(" + " ".join(section_names) + ")", 'entropy': str(entropy),
                           'machine': str(machine), 'time': str(time_date_stamp),
                           'number_of_sections': str(number_of_sections), 'image_base': str(image_base),
                           'section_align': str(section_allign), 'file_align': str(file_allign),
                           'size_of_image': str(size_of_image), 'dll_chars': str(dll_chars)}])

        create_col_unusual_names(file_to_predict)
        file_to_predict = file_to_predict.drop(columns=['pe_section_names', 'time'])
        file_to_predict = pd.get_dummies(file_to_predict,
                                         columns=["unusual_names", "machine", "image_base",
                                                  "section_align", "file_align"])

    else:
        print("File not a PE file, make sure it ends with .exe")
        return

    return file_to_predict

# tree classifier to add to the program at later
# def tree_classifier():
#    malware_data = pd.read_csv('ml_data.csv', delimiter=",")
#    target_labels = pd.read_csv('target.csv', delimiter=",")
#   minmaxscaler = preprocessing.MinMaxScaler.fit(malware_data)

#    train, test, target_train, target_test = train_test_split(malware_data, target_labels, test_size=0.2,
#                                                              random_state=33)

#    tree_classifier_mal = tree.DecisionTreeClassifier(criterion='entropy', min_samples_split=3)
#   tree_classifier_mal.fit(train, target_train.values.ravel())

#   return tree_classifier_mal, minmaxscaler


def knn(input_point):
    malware_data = pd.read_csv('data-not-normalized.csv', delimiter=",")
    target_labels = pd.read_csv('target.csv', delimiter=",")

    train, test, target_train, target_test = train_test_split(malware_data, target_labels, test_size=0.2,
                                                              random_state=33)

    train = train[['unusual_names_no', 'unusual_names_yes', 'number_of_sections', 'entropy']]
    min_max_scaler = preprocessing.MinMaxScaler().fit(train)
    train_norm = min_max_scaler.transform(train)

    target_train = np.array(target_train)

    n_neighbors = 10
    knn_classifier_malware = neighbors.KNeighborsClassifier(n_neighbors, metric='euclidean')
    knn_classifier_malware.fit(train_norm, target_train.ravel())

    input_point_norm = min_max_scaler.transform(input_point)

    return knn_classifier_malware.predict(input_point_norm)


###################################################################################################################
# The user input section
###################################################################################################################


predict_new_malware = "y"

while predict_new_malware == "y":
    print("""
    ********************************************************************************************************
    Welcome to Malware Predictor 1.0. By entering in a PE file you can see if it is an instance of malware
    or not. The prediction is based on the K-nearest-neighbor algorithm.
    By Wills Mckenna, 3/7/2021.
    ******************************************************************************************************** 
    """)

    file_path = input("Enter full path of file you want to classify: ")

    df = parse_file(file_path)
    if df is None:
        print("Aborting...")
        break

    add_dummy_features(df)
    df = df[['unusual_names_no', 'unusual_names_yes', 'number_of_sections', 'entropy']]

    prediction = knn(df)

    print(f"""
    RESULT
    ---------------------------------------------------------------------------------------------------------
    Is the file you entered malware? Prediction: {prediction}.
    """)

    predict_new_malware = input("Enter another file to classify? (y/n)")

print("Exiting program....")


